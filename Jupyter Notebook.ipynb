{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790de3ea-8bc8-4719-aae2-b57989c79bd2",
   "metadata": {},
   "source": [
    "# Step 1: Load the Dataset\n",
    "## First, we load the dataset using Pandas. This allows us to view and manipulate the data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0024f4-373d-46e4-885c-ab02c89db271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\ZAIN NIZAR YOUSAF\\\\Downloads\\\\employee.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4611dffc-c72e-4704-93a7-1f6b800d8a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Person Name                Organization                      Job  \\\n",
      "0    Amis, Beatrice J.  PN - Neighborhood Services       Front Desk/Cashier   \n",
      "1     Blight, Linda A.  PN - Neighborhood Services            Instructor  3   \n",
      "2          Bowden, Tim          PW - Environmental  Sr Maintenance Mechanic   \n",
      "3       Burton, Robert     PN - Parks & Recreation                  Monitor   \n",
      "4  Cisneros, Alejandro     PN - Parks & Recreation            Instructor  3   \n",
      "\n",
      "  Work Group  Gross Wages  Base Salary Longevity Pay  Overtime     Other  \\\n",
      "0       HRLY   $8,122.36    $8,122.36         $0.00     $0.00     $0.00    \n",
      "1       HRLY   $3,516.25    $3,516.25         $0.00     $0.00     $0.00    \n",
      "2        CEA  $86,965.55   $76,514.36     $7,651.57   $127.02   $125.00    \n",
      "3       HRLY   $4,232.29    $4,232.29         $0.00     $0.00     $0.00    \n",
      "4       HRLY   $1,120.00    $1,120.00         $0.00     $0.00     $0.00    \n",
      "\n",
      "  Seperation Pay Annual Buybacks PERS Contributions ER Paid Other Benefits  \\\n",
      "0         $0.00           $0.00              $0.00   $0.00      $1,218.35    \n",
      "1         $0.00           $0.00              $0.00   $0.00        $527.44    \n",
      "2         $0.00       $2,547.60         $21,235.98   $0.00     $14,349.32    \n",
      "3         $0.00           $0.00              $0.00   $0.00        $634.84    \n",
      "4         $0.00           $0.00              $0.00   $0.00        $168.00    \n",
      "\n",
      "       Year Ending  \n",
      "0  12/31/2012 0:00  \n",
      "1  12/31/2012 0:00  \n",
      "2  12/31/2012 0:00  \n",
      "3  12/31/2012 0:00  \n",
      "4  12/31/2012 0:00  \n"
     ]
    }
   ],
   "source": [
    "# View the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdabfdc-2b97-47ea-bc6d-a831c415fd03",
   "metadata": {},
   "source": [
    "# Step 2: Understand the Data Structure\n",
    "## Next, we inspect the dataset to understand its structure. This includes checking the data types, non-null counts, and summary statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50c08ad-589b-48b9-8d79-6b7807e02393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22115 entries, 0 to 22114\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Person Name         22115 non-null  object\n",
      " 1   Organization        22115 non-null  object\n",
      " 2   Job                 22115 non-null  object\n",
      " 3   Work Group          22115 non-null  object\n",
      " 4   Gross Wages         22111 non-null  object\n",
      " 5   Base Salary         22104 non-null  object\n",
      " 6   Longevity Pay       15370 non-null  object\n",
      " 7   Overtime            16213 non-null  object\n",
      " 8   Other               17887 non-null  object\n",
      " 9   Seperation Pay      11433 non-null  object\n",
      " 10  Annual Buybacks     14803 non-null  object\n",
      " 11  PERS Contributions  15547 non-null  object\n",
      " 12  ER Paid             18863 non-null  object\n",
      " 13  Other Benefits      22115 non-null  object\n",
      " 14  Year Ending         22115 non-null  object\n",
      "dtypes: object(15)\n",
      "memory usage: 2.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get general info about the dataset (datatypes, non-null counts)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1781392-3a9a-406a-8132-57cd590d3fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Person Name      Organization                     Job Work Group  \\\n",
      "count            22115             22115                   22115      22115   \n",
      "unique            6338               126                     585         16   \n",
      "top     Wood, David R.  FR - Suppression  Safekey Site Assistant        CEA   \n",
      "freq                 9              3485                    1641       7416   \n",
      "\n",
      "       Gross Wages Base Salary Longevity Pay Overtime   Other Seperation Pay  \\\n",
      "count        22111       22104         15370    16213   17887          11433   \n",
      "unique       20931       19380          7368     9829    7353            865   \n",
      "top     $5,944.43   $5,944.43         $0.00    $0.00   $0.00          $0.00    \n",
      "freq            22          24          6373     6040    4623          10566   \n",
      "\n",
      "       Annual Buybacks PERS Contributions ER Paid Other Benefits  \\\n",
      "count            14803              15547   18863          22115   \n",
      "unique            6129              13110    1155           4836   \n",
      "top             $0.00              $0.00   $0.00          $0.00    \n",
      "freq              7160               1941   10605          16219   \n",
      "\n",
      "            Year Ending  \n",
      "count             22115  \n",
      "unique                6  \n",
      "top     12/31/2017 0:00  \n",
      "freq               3957  \n"
     ]
    }
   ],
   "source": [
    "# Get summary statistics for numerical columns\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c79d8f-e1e2-40b2-a5c1-bb614396ac49",
   "metadata": {},
   "source": [
    "# Step 3: Handle Missing Data\n",
    "## Missing values are common in real-world datasets. Here, we can choose to either drop rows with missing data or fill them with a placeholder (e.g., the mean of the column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1902e432-f014-4bbf-870f-dd82587ced08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person Name               0\n",
      "Organization              0\n",
      "Job                       0\n",
      "Work Group                0\n",
      "Gross Wages               4\n",
      "Base Salary              11\n",
      "Longevity Pay          6745\n",
      "Overtime               5902\n",
      "Other                  4228\n",
      "Seperation Pay        10682\n",
      "Annual Buybacks        7312\n",
      "PERS Contributions     6568\n",
      "ER Paid                3252\n",
      "Other Benefits            0\n",
      "Year Ending               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1831814-b39c-4f72-b0cf-3b28d02243a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in categorical columns with 'Nill'\n",
    "df['Gross Wages'] = df['Gross Wages'].fillna(\"$0.00\")\n",
    "df['Base Salary'] = df['Base Salary'].fillna(\"$0.00\")\n",
    "df['Longevity Pay'] = df['Longevity Pay'].fillna(\"$0.00\")\n",
    "df['Overtime'] = df['Overtime'].fillna(\"$0.00\")\n",
    "df['Other'] = df['Other'].fillna(\"$0.00\")\n",
    "df['Seperation Pay '] = df['Seperation Pay'].fillna(\"$0.00\")\n",
    "df['Annual Buybacks'] = df['Annual Buybacks'].fillna(\"$0.00\")\n",
    "df['PERS Contributions'] = df['PERS Contributions'].fillna(\"$0.00\")\n",
    "df['ER Paid '] = df['ER Paid'].fillna(\"$0.00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ba95d-f79d-4e71-bc67-2f1b4eac2338",
   "metadata": {},
   "source": [
    "# Step 4: Handle Duplicates\n",
    "## Duplicate rows can distort the analysis or model predictions. We need to check for and remove any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c99a4972-d360-4007-9a08-4922492cf307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06bfab1-66e4-4849-9bba-fb0c2036216f",
   "metadata": {},
   "source": [
    "# Step 5: Data Transformation\n",
    "\n",
    "## 5.1 Encode Categorical Variables\n",
    "### Categorical columns like \"Organization\", \"Job\", and \"Work Group\" need to be converted to numerical values  to be used in machine learning algorithms. We can use one-hot encoding or label encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64bbdebc-34cf-4b73-84e5-66f9609ff02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pd.get_dummies for one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Organization', 'Job', 'Work Group'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05777e39-7c36-46c1-b3a2-051f5fb8e2e8",
   "metadata": {},
   "source": [
    "# 5.2 Scale Numerical Features\n",
    "## Numerical columns need to be scaled to ensure the model treats all features equally.  We use the StandardScaler to standardize numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8fce43f-c6a6-46fc-87e6-174089c25e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Gross Wages   Base Salary  Longevity Pay      Overtime         Other  \\\n",
      "count  2.211100e+04  2.210400e+04   1.537000e+04  1.621000e+04  1.787600e+04   \n",
      "mean   2.056657e-17 -1.028654e-17  -2.958669e-17  7.013377e-18  9.539621e-18   \n",
      "std    1.000023e+00  1.000023e+00   1.000033e+00  1.000031e+00  1.000028e+00   \n",
      "min   -1.298272e+00 -1.396228e+00  -9.560672e-01 -5.679479e-01 -6.643864e-01   \n",
      "25%   -1.106689e+00 -1.151387e+00  -9.560672e-01 -5.679479e-01 -6.643864e-01   \n",
      "50%    6.724391e-02  1.863856e-01  -1.519404e-01 -5.152798e-01 -3.530324e-01   \n",
      "75%    6.830296e-01  7.790039e-01   8.102239e-01  9.123405e-02  2.168901e-01   \n",
      "max    5.322373e+00  5.602580e+00   4.480692e+00  9.177510e+00  3.219616e+01   \n",
      "\n",
      "       Separation Pay  Annual Buybacks  PERS Contributions       ER Paid  \\\n",
      "count    1.143300e+04     1.480200e+04        1.546700e+04  1.886200e+04   \n",
      "mean     1.988749e-17     7.680505e-18       -1.837571e-17  2.410918e-17   \n",
      "std      1.000044e+00     1.000034e+00        1.000032e+00  1.000027e+00   \n",
      "min     -1.748962e-01    -4.618495e-01       -1.510343e+00 -7.825371e-01   \n",
      "25%     -1.748962e-01    -4.618495e-01       -6.318164e-01 -7.825371e-01   \n",
      "50%     -1.748962e-01    -3.435179e-01       -6.296587e-02 -7.825371e-01   \n",
      "75%     -1.748962e-01     1.628654e-01        6.575514e-01  8.395838e-01   \n",
      "max      1.509472e+01     2.268195e+01        6.324957e+00  2.218750e+00   \n",
      "\n",
      "       Other Benefits  \n",
      "count    2.211100e+04  \n",
      "mean    -1.028328e-16  \n",
      "std      1.000023e+00  \n",
      "min     -3.763791e-01  \n",
      "25%     -3.763791e-01  \n",
      "50%     -3.763791e-01  \n",
      "75%     -3.454336e-01  \n",
      "max      9.367267e+00  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale numerical columns\n",
    "df[['Gross Wages', 'Base Salary', 'Longevity Pay', 'Overtime', 'Other', \n",
    "    'Separation Pay', 'Annual Buybacks', 'PERS Contributions', 'ER Paid', \n",
    "    'Other Benefits']] = scaler.fit_transform(df[['Gross Wages', 'Base Salary', \n",
    "                                                 'Longevity Pay', 'Overtime', \n",
    "                                                 'Other', 'Seperation Pay', \n",
    "                                                 'Annual Buybacks', 'PERS Contributions', \n",
    "                                                 'ER Paid', 'Other Benefits']])\n",
    "\n",
    "# View the summary statistics to check the scaling result\n",
    "print(df[['Gross Wages', 'Base Salary', 'Longevity Pay', 'Overtime', 'Other', \n",
    "          'Separation Pay', 'Annual Buybacks', 'PERS Contributions', 'ER Paid', \n",
    "          'Other Benefits']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69a177-45be-49bb-b318-3ec22b4299e9",
   "metadata": {},
   "source": [
    "# Step 6: Handle Outliers\n",
    "## Outliers can distort the results of statistical analysis or machine learning models.  We'll handle outliers using two common methods: Z-scores and IQR (Interquartile Range).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28ade5a9-9551-4842-a47c-40ce1ef21f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing outliers, dataset shape: (0, 739)\n",
      "After removing outliers, dataset shape: (0, 739)\n",
      "Empty DataFrame\n",
      "Columns: [Person Name, Gross Wages, Base Salary, Longevity Pay, Overtime, Other, Seperation Pay, Annual Buybacks, PERS Contributions, ER Paid, Other Benefits, Year Ending, Seperation Pay , ER Paid , Organization_BS - Admin, Organization_BS - Code Enforcement, Organization_BS - Customer Service, Organization_BS - Inspections, Organization_BS - Permits, Organization_CA - Admin, Organization_CA - Civil, Organization_CA - Civil Litigation Team, Organization_CA - Criminal, Organization_CA - Victim Witness Program, Organization_CC Office of the City Clerk, Organization_CM - Admin, Organization_CO Office of the City Council, Organization_CS - Admin, Organization_CS - Community Partnerships, Organization_CS - Community Partnerships-Safekey, Organization_CS - Community Resources, Organization_CS - Human Services, Organization_DE - Animal Control, Organization_DE - City Marshals, Organization_DE - Det & Correction Operations, Organization_DE - Detention and Correction Operations, Organization_DE - Parking Enforcement, Organization_DPS - Animal Control, Organization_DPS - City Marshals, Organization_DPS - Detention and Correction Operations, Organization_DS Development Services Center, Organization_EU - Admin, Organization_EU - Business Development, Organization_EU - Economic Development, Organization_EU - Economic Development Asset Mgmt, Organization_EU - Neighborhood Development, Organization_EU - Parking, Organization_EU - Redevelopment, Organization_FB - Accounting Operations, Organization_FB - Admin, Organization_FB - Finance and Budget, Organization_FB - Financial Services, Organization_FB - Purchasing & Contracts, Organization_FB - Purchasing and Contracts, Organization_FB - Strategic Analysis & Reporting, Organization_FB - Strategic Analysis and Reporting, Organization_FR - Admin, Organization_FR - Fire Communications, Organization_FR - Fire Prevention Services, Organization_FR - Support Services, Organization_FR - Suppression, Organization_FR - Training, Organization_HR - Admin, Organization_HR - Employee & Labor Relations, Organization_HR - Employee and Labor Relations, Organization_HR - RES-Substitute Program, Organization_HR - Recruitment & Employment Svcs, Organization_HR - Recruitment and Employment Services, Organization_HR - Risk Compensation and Benefits, Organization_HR - Risk, Compensation & Benefits, Organization_IT - Admin, Organization_IT - Application Services, Organization_IT - Communications, Organization_IT - Computer Services, Organization_IT - Print Media, Organization_IT - Program Management Office, Organization_IT - System Infrastructure, Organization_IT - System/Infrastructure, Organization_LS - Adaptive Programming, Organization_LS - Arts & Community Events, Organization_LS - Sr Citizens Programming, Organization_MA Office of the Mayor, Organization_MC - ASED Alternative Sentencing and Education, Organization_MC - Admin, Organization_MC - Administrative Services, Organization_MC - Courtroom Services, Organization_MC - Courtroom Support, Organization_MC - Courtroom Support OLD ORG, Organization_MC - Courtroom Support Services, Organization_MC - Criminal, Organization_MC - Judges, Organization_MC - LEAR, Organization_MC - Security and Enforcement, Organization_MC - Traffic, Organization_NS - Neighborhood Development, Organization_NS - Neighborhood Response, Organization_OA Office of Cultural Affairs, Organization_OC Office of Communications, Organization_OM - Admin, Organization_OM - Facilities Management, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 739 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = stats.zscore(df[['Gross Wages', 'Base Salary', 'Longevity Pay', \n",
    "                            'Overtime', 'Other', 'Separation Pay', 'Annual Buybacks', \n",
    "                            'PERS Contributions', 'ER Paid', 'Other Benefits']])\n",
    "\n",
    "# Set a threshold (usually 3) for outliers\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "\n",
    "# Before filtering, print the shape of the DataFrame to see the number of rows\n",
    "print(\"Before removing outliers, dataset shape:\", df.shape)\n",
    "\n",
    "# Remove rows where any of the Z-scores is greater than 3 (outliers)\n",
    "df_cleaned = df[(abs_z_scores < 3).all(axis=1)]\n",
    "\n",
    "# After filtering, print the shape of the DataFrame to see how many rows remain\n",
    "print(\"After removing outliers, dataset shape:\", df_cleaned.shape)\n",
    "\n",
    "# Optionally, you can also print the first few rows of the cleaned dataset to check the data\n",
    "print(df_cleaned.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993bddc-ceba-49cf-903e-0f7ab26cae27",
   "metadata": {},
   "source": [
    "# 6.2 Using IQR (Interquartile Range)\n",
    "## Calculate the 1st (Q1) and 3rd (Q3) quartiles, and use the IQR to detect outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e596c0e-3624-49c3-b34c-2161ba345deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing outliers using IQR, dataset shape: (0, 739)\n",
      "After removing outliers using IQR, dataset shape: (0, 739)\n",
      "Empty DataFrame\n",
      "Columns: [Person Name, Gross Wages, Base Salary, Longevity Pay, Overtime, Other, Seperation Pay, Annual Buybacks, PERS Contributions, ER Paid, Other Benefits, Year Ending, Seperation Pay , ER Paid , Organization_BS - Admin, Organization_BS - Code Enforcement, Organization_BS - Customer Service, Organization_BS - Inspections, Organization_BS - Permits, Organization_CA - Admin, Organization_CA - Civil, Organization_CA - Civil Litigation Team, Organization_CA - Criminal, Organization_CA - Victim Witness Program, Organization_CC Office of the City Clerk, Organization_CM - Admin, Organization_CO Office of the City Council, Organization_CS - Admin, Organization_CS - Community Partnerships, Organization_CS - Community Partnerships-Safekey, Organization_CS - Community Resources, Organization_CS - Human Services, Organization_DE - Animal Control, Organization_DE - City Marshals, Organization_DE - Det & Correction Operations, Organization_DE - Detention and Correction Operations, Organization_DE - Parking Enforcement, Organization_DPS - Animal Control, Organization_DPS - City Marshals, Organization_DPS - Detention and Correction Operations, Organization_DS Development Services Center, Organization_EU - Admin, Organization_EU - Business Development, Organization_EU - Economic Development, Organization_EU - Economic Development Asset Mgmt, Organization_EU - Neighborhood Development, Organization_EU - Parking, Organization_EU - Redevelopment, Organization_FB - Accounting Operations, Organization_FB - Admin, Organization_FB - Finance and Budget, Organization_FB - Financial Services, Organization_FB - Purchasing & Contracts, Organization_FB - Purchasing and Contracts, Organization_FB - Strategic Analysis & Reporting, Organization_FB - Strategic Analysis and Reporting, Organization_FR - Admin, Organization_FR - Fire Communications, Organization_FR - Fire Prevention Services, Organization_FR - Support Services, Organization_FR - Suppression, Organization_FR - Training, Organization_HR - Admin, Organization_HR - Employee & Labor Relations, Organization_HR - Employee and Labor Relations, Organization_HR - RES-Substitute Program, Organization_HR - Recruitment & Employment Svcs, Organization_HR - Recruitment and Employment Services, Organization_HR - Risk Compensation and Benefits, Organization_HR - Risk, Compensation & Benefits, Organization_IT - Admin, Organization_IT - Application Services, Organization_IT - Communications, Organization_IT - Computer Services, Organization_IT - Print Media, Organization_IT - Program Management Office, Organization_IT - System Infrastructure, Organization_IT - System/Infrastructure, Organization_LS - Adaptive Programming, Organization_LS - Arts & Community Events, Organization_LS - Sr Citizens Programming, Organization_MA Office of the Mayor, Organization_MC - ASED Alternative Sentencing and Education, Organization_MC - Admin, Organization_MC - Administrative Services, Organization_MC - Courtroom Services, Organization_MC - Courtroom Support, Organization_MC - Courtroom Support OLD ORG, Organization_MC - Courtroom Support Services, Organization_MC - Criminal, Organization_MC - Judges, Organization_MC - LEAR, Organization_MC - Security and Enforcement, Organization_MC - Traffic, Organization_NS - Neighborhood Development, Organization_NS - Neighborhood Response, Organization_OA Office of Cultural Affairs, Organization_OC Office of Communications, Organization_OM - Admin, Organization_OM - Facilities Management, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 739 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate IQR for each numerical column\n",
    "Q1 = df[['Gross Wages', 'Base Salary', 'Longevity Pay', 'Overtime', 'Other', \n",
    "         'Separation Pay', 'Annual Buybacks', 'PERS Contributions', \n",
    "         'ER Paid', 'Other Benefits']].quantile(0.25)\n",
    "Q3 = df[['Gross Wages', 'Base Salary', 'Longevity Pay', 'Overtime', 'Other', \n",
    "         'Separation Pay', 'Annual Buybacks', 'PERS Contributions', \n",
    "         'ER Paid', 'Other Benefits']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Before filtering, print the shape of the DataFrame to see the number of rows\n",
    "print(\"Before removing outliers using IQR, dataset shape:\", df.shape)\n",
    "\n",
    "# Filter out outliers using IQR method\n",
    "df_cleaned_iqr = df[~((df[['Gross Wages', 'Base Salary', 'Longevity Pay', 'Overtime', 'Other', \n",
    "                           'Separation Pay', 'Annual Buybacks', 'PERS Contributions', \n",
    "                           'ER Paid', 'Other Benefits']] < (Q1 - 1.5 * IQR)) | \n",
    "                      (df[['Gross Wages', 'Base Salary', 'Longevity Pay', 'Overtime', 'Other', \n",
    "                           'Separation Pay', 'Annual Buybacks', 'PERS Contributions', \n",
    "                           'ER Paid', 'Other Benefits']] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# After filtering, print the shape of the DataFrame to see how many rows remain\n",
    "print(\"After removing outliers using IQR, dataset shape:\", df_cleaned_iqr.shape)\n",
    "\n",
    "# Optionally, you can also print the first few rows of the cleaned dataset to check the data\n",
    "print(df_cleaned_iqr.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f85e18e-f499-446e-9329-18032db57d97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear Ending\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets (80% training, 20% testing)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2780\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2410\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2407\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2414\u001b[0m     )\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define feature columns (X) and target variable (y)\n",
    "X = df.drop(columns=['Year Ending'])  # Assuming 'Year Ending' is the target variable\n",
    "y = df['Year Ending']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe0a03-db5d-448d-9db8-e6f07385c9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
